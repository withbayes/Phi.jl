name: CI
on:
  push:
    branches:
      - main
    tags: ['*']
  pull_request:
  schedule:
    - cron:  '28 0,6,12,18 * * *'
concurrency:
  # Skip intermediate builds: always.
  # Cancel intermediate builds: only if it is a pull request build.
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ startsWith(github.ref, 'refs/pull/') }}
jobs:
  test:
    name: ${{ matrix.test_group }}
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule'
    strategy:
      fail-fast: false
      matrix:
        test_group:
          - 'basic'
          - 'rrules'
          - 'integration_testing/misc'
          - 'integration_testing/diff_tests'
          - 'integration_testing/distributions'
          - 'integration_testing/gp'
          - 'integration_testing/special_functions'
          - 'integration_testing/array'
          - 'integration_testing/turing'
          - 'integration_testing/temporalgps'
          - 'integration_testing/lux'
          - 'interface'
    steps:
      - uses: actions/checkout@v4
      - uses: julia-actions/setup-julia@v2
        with:
          version: '1'
          arch: x64
          include-all-prereleases: false
      - uses: julia-actions/cache@v2
      - uses: julia-actions/julia-buildpkg@v1
      - uses: julia-actions/julia-runtest@v1
        env:
          TEST_GROUP: ${{ matrix.test_group }}
  perf:
    name: "Performance (${{ matrix.perf_group }})"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        perf_group:
          - 'hand_written'
          - 'derived'
    steps:
      - uses: actions/checkout@v4
      - uses: julia-actions/setup-julia@v2
        with:
          version: '1'
          arch: x64
          include-all-prereleases: false
      - uses: julia-actions/cache@v2
      - uses: julia-actions/julia-buildpkg@v1
      - run: julia --project=bench --eval 'include("bench/run_benchmarks.jl"); main()'
        env:
          PERF_GROUP: ${{ matrix.perf_group }}
        shell: bash
  compperf:
    name: "Performance (inter-AD)"
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    strategy:
      fail-fast: false
    steps:
      - uses: actions/checkout@v4
      - uses: julia-actions/setup-julia@v2
        with:
          version: '1'
          arch: x64
          include-all-prereleases: false
      - uses: julia-actions/cache@v2
      - uses: julia-actions/julia-buildpkg@v1
      - run: mkdir bench_results
      - run: julia --project=bench --eval 'include("bench/run_benchmarks.jl"); main()'
        env:
          PERF_GROUP: 'comparison'
          GKSwstype: '100'
        shell: bash
      - uses: actions/upload-artifact@v4
        with:
          name: benchmarking-results
          path: bench_results/
      # Useful code for testing action.
      # - run: |
      #     text="this is line one
      #     this is line two
      #     this is line three"
      #     echo "$text" > benchmark_results.txt
      - name: Read file content
        id: read-file
        run: |
          {
            echo "table<<EOF"
            cat bench/benchmark_results.txt
            echo "EOF"
          } >> $GITHUB_OUTPUT
      - name: Find Comment
        uses: peter-evans/find-comment@v3
        id: fc
        with:
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: github-actions[bot]
      - id: post-report-as-pr-comment
        name: Post Report as Pull Request Comment
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: "Performance Ratio:\nWarning: results are very approximate!\n```\n${{ steps.read-file.outputs.table }}\n```"
          comment-id: ${{ steps.fc.outputs.comment-id }}
          edit-mode: replace
